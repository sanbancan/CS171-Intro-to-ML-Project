# CS 171 Final Project

# ðŸ§Š Iceberg vs Ship Detection CNN (CS171 Intro to ML)

**Final Results**: 77.5% test accuracy (+19.5% over 58% baseline) on satellite imagery classification

[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sanbancan/CS171-Intro-to-ML-Project/blob/main/notebooks/Full_Run.ipynb)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

## ðŸŽ¯ Project Overview
Classify 75Ã—75px satellite images as **icebergs** or **ships** for maritime safety. Dataset: 1,604 train / 8,424 test images.

**Baseline**: 58% test accuracy â†’ **Final**: 77.5% test accuracy (F1: 0.76)

## ðŸ“ Repository Structure
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_eda.ipynb # Exploratory Data Analysis
â”‚ â”œâ”€â”€ 02_data_preprocessing_sania.ipynb # SANIA: Normalization + Augmentation
â”‚ â”œâ”€â”€ 03_model_training_victoria.ipynb # Victoria: Initial architectures
â”‚ â”œâ”€â”€ 04_model_evaluation_sania.ipynb # SANIA: Metrics + Comparisons
â”‚ â””â”€â”€ Full_Run.ipynb # End-to-end pipeline
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ baseline_logistic.py # Simple baseline
â”‚ â”‚ â”œâ”€â”€ victoria_cnn_v1.py # Victoria: 3-layer CNN
â”‚ â”‚ â””â”€â”€ sania_cnn_v2.py # SANIA: 4-layer CNN (best model)
â”‚ â”œâ”€â”€ data/
â”‚ â”‚ â””â”€â”€ preprocessing.py # Data pipeline
â”‚ â””â”€â”€ utils/
â”‚ â””â”€â”€ metrics.py # F1, confusion matrix
â”œâ”€â”€ experiments/
â”‚ â””â”€â”€ hyperparameter_log_sania.csv # SANIA: 23 experiments tracked
â”œâ”€â”€ data/ # Sample images (not full dataset)
â”œâ”€â”€ results/
â”‚ â”œâ”€â”€ train_val_curves.png # Overfitting visualization
â”‚ â””â”€â”€ confusion_matrix_best.png # Final model performance
â””â”€â”€ requirements.txt


## ðŸ”§ My Contributions (Sania Bandekar)
1. **Data Pipeline** (`02_data_preprocessing_sania.ipynb`): Normalization, augmentation (rotation/flip/brightness), class balancing
2. **Best CNN Architecture** (`sania_cnn_v2.py`): 4-layer (64â†’128â†’256â†’512 filters), 77.5% test accuracy
3. **Evaluation Framework** (`04_model_evaluation_sania.ipynb`): 5 architectures compared, F1-metrics, CV
4. **Hyperparameter Tracking** (`hyperparameter_log_sania.csv`): 23 experiments (batch_size, dropout, epochs)

## ðŸ“Š Key Results
| Model | Test Acc | Test F1 | Train Acc | Val Acc |
|-------|----------|---------|-----------|---------|
| Logistic Baseline | 58.2% | 0.57 | - | - |
| Victoria CNN v1 (3-layer) | 68.4% | 0.67 | 89% | 65% |
| **Sania CNN v2 (4-layer)** | **77.5%** | **0.76** | 94% | 73% |

## ðŸ› ï¸ Technical Decisions
Architecture: Conv2D(64) â†’ MaxPool â†’ Conv2D(128) â†’ Dropout(0.2) â†’
Conv2D(256) â†’ Conv2D(512) â†’ GlobalAvgPool â†’ Dense(1, sigmoid)

Hyperparameters:

Optimizer: Adam(lr=0.001)

Batch Size: 16 (vs 32, smoother gradients)

Epochs: 75

Augmentation: rotation=10Â°, flip, brightness Â±10%


## ðŸš€ Quick Start
```bash
pip install -r requirements.txt
python src/models/sania_cnn_v2.py --train

ðŸŽ“ Key Learnings
Data augmentation prevented 30% overfitting

Smaller batch_size=16 > batch_size=32 for small datasets

F1-score > accuracy for imbalanced classes


