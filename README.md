# CS 171 Final Project

# ðŸ§Š Iceberg vs Ship Detection CNN (CS171 Intro to ML)

**Final Results**: 77.5% test accuracy (+19.5% over 58% baseline) on satellite imagery classification

[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sanbancan/CS171-Intro-to-ML-Project/blob/main/notebooks/Full_Run.ipynb)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

## ðŸŽ¯ Project Overview
Classify 75Ã—75px satellite images as **icebergs** or **ships** for maritime safety. Dataset: 1,604 train / 8,424 test images.

**Baseline**: 58% test accuracy â†’ **Final**: 77.5% test accuracy (F1: 0.76)

## ðŸ“ Repository Structure
CS171-Intro-to-ML-Project/
â”œâ”€â”€ README.md                 
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_eda_victoria.ipynb
â”‚   â”œâ”€â”€ 01_data_preprocessing_sania.ipynb  â† **SANIA**
â”‚   â””â”€â”€ 03_model_experiments_sania.ipynb   â† **SANIA**
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preparation.py              â† **SANIA**
â”‚   â”œâ”€â”€ train_sania.py                   â† **SANIA**
â”‚   â”œâ”€â”€ baseline_victoria.py
â”‚   â””â”€â”€ model_architectures.py
â”œâ”€â”€ data/                 â† sample_data.csv (10 images)
â”œâ”€â”€ results/              â† accuracy_plots.png, experiment_log.csv
â””â”€â”€ requirements.txt



## ðŸ”§ My Contributions (Sania Bandekar)
1. **Data Pipeline** (`02_data_preprocessing_sania.ipynb`): Normalization, augmentation (rotation/flip/brightness), class balancing
2. **Best CNN Architecture** (`sania_cnn_v2.py`): 4-layer (64â†’128â†’256â†’512 filters), 77.5% test accuracy
3. **Evaluation Framework** (`04_model_evaluation_sania.ipynb`): 5 architectures compared, F1-metrics, CV
4. **Hyperparameter Tracking** (`hyperparameter_log_sania.csv`): 23 experiments (batch_size, dropout, epochs)

## ðŸ“Š Key Results
| Model | Test Acc | Test F1 | Train Acc | Val Acc |
|-------|----------|---------|-----------|---------|
| Logistic Baseline | 58.2% | 0.57 | - | - |
| Victoria CNN v1 (3-layer) | 68.4% | 0.67 | 89% | 65% |
| **Sania CNN v2 (4-layer)** | **77.5%** | **0.76** | 94% | 73% |

## ðŸ› ï¸ Technical Decisions
Architecture: Conv2D(64) â†’ MaxPool â†’ Conv2D(128) â†’ Dropout(0.2) â†’
Conv2D(256) â†’ Conv2D(512) â†’ GlobalAvgPool â†’ Dense(1, sigmoid)

Hyperparameters:

Optimizer: Adam(lr=0.001)

Batch Size: 16 (vs 32, smoother gradients)

Epochs: 75

Augmentation: rotation=10Â°, flip, brightness Â±10%


## ðŸš€ Quick Start
```bash
pip install -r requirements.txt
python src/models/sania_cnn_v2.py --train

ðŸŽ“ Key Learnings
Data augmentation prevented 30% overfitting

Smaller batch_size=16 > batch_size=32 for small datasets

F1-score > accuracy for imbalanced classes


